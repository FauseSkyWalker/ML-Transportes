#!/usr/bin/env python3
"""
AnÃ¡lise do Dataset Sem Nulos PESID - PBIC
Script para analisar o dataset removendo registros com pesid nulo
"""

import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# ConfiguraÃ§Ãµes
pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', 50)

def analisar_dataset_sem_nulos():
    """Analisa o dataset removendo registros com pesid nulo"""
    print("ðŸ” ANÃLISE DO DATASET SEM NULOS EM PESID")
    print("="*60)
    
    # Carrega o dataset limpo
    try:
        df = pd.read_csv('acidentes_pbic_2020_2025_limpo.csv')
        print(f"âœ… Dataset original carregado: {len(df):,} registros")
        print(f"ðŸ“Š Total de colunas: {len(df.columns)}")
        
        # Remove registros com pesid nulo
        df_filtrado = df.dropna(subset=['pesid'])
        registros_removidos = len(df) - len(df_filtrado)
        percentual_removido = (registros_removidos / len(df)) * 100
        
        print(f"ðŸ“‰ Registros removidos: {registros_removidos:,} ({percentual_removido:.1f}%)")
        print(f"âœ… Dataset filtrado: {len(df_filtrado):,} registros")
        
    except FileNotFoundError:
        print("âŒ Arquivo 'acidentes_pbic_2020_2025_limpo.csv' nÃ£o encontrado!")
        return
    
    # Verifica valores nulos
    print(f"\nðŸ” VALORES NULOS POR COLUNA:")
    valores_nulos = df_filtrado.isnull().sum()
    colunas_com_nulos = valores_nulos[valores_nulos > 0].sort_values(ascending=False)
    
    if len(colunas_com_nulos) > 0:
        for coluna, qtd_nulos in colunas_com_nulos.items():
            percentual = (qtd_nulos / len(df_filtrado)) * 100
            print(f"   â€¢ {coluna}: {qtd_nulos:,} ({percentual:.1f}%)")
    else:
        print("   âœ… Nenhuma coluna com valores nulos!")
    
    # Acidentes Ãºnicos vs pessoas
    print(f"\nðŸš— ACIDENTES vs PESSOAS:")
    if 'id' in df_filtrado.columns:
        acidentes_unicos = df_filtrado['id'].nunique()
        pessoas_total = len(df_filtrado)
        media_pessoas_por_acidente = pessoas_total / acidentes_unicos
        
        print(f"   â€¢ Acidentes Ãºnicos: {acidentes_unicos:,}")
        print(f"   â€¢ Pessoas envolvidas: {pessoas_total:,}")
        print(f"   â€¢ MÃ©dia pessoas/acidente: {media_pessoas_por_acidente:.1f}")
    
    # DistribuiÃ§Ã£o por ano
    print(f"\nðŸ“… DISTRIBUIÃ‡ÃƒO POR ANO:")
    if 'ano_arquivo' in df_filtrado.columns:
        dist_ano = df_filtrado['ano_arquivo'].value_counts().sort_index()
        for ano, qtd in dist_ano.items():
            print(f"   â€¢ {ano}: {qtd:,} pessoas")
    
    # DistribuiÃ§Ã£o de gravidade
    if 'gravidade_numerica' in df_filtrado.columns:
        print(f"\nðŸš‘ DISTRIBUIÃ‡ÃƒO DE GRAVIDADE:")
        gravidade_labels = {0: 'Sem VÃ­timas', 1: 'Feridos Leves', 2: 'Feridos Graves', 3: 'Mortos'}
        dist_gravidade = df_filtrado['gravidade_numerica'].value_counts().sort_index()
        
        for nivel, qtd in dist_gravidade.items():
            label = gravidade_labels.get(nivel, f'NÃ­vel {nivel}')
            percentual = (qtd / len(df_filtrado)) * 100
            print(f"   â€¢ {label}: {qtd:,} ({percentual:.1f}%)")
    
    print(f"\nâœ… AnÃ¡lise concluÃ­da!")

if __name__ == "__main__":
    analisar_dataset_sem_nulos()
